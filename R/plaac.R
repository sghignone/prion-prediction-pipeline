#!/usr/bin/env Rscript

################################################################################
# PLAAC Launcher for Prion Domain Prediction Pipeline (v1.0)
################################################################################
# Standalone wrapper to run PLAAC (Prion-Like Amino Acid Composition) analysis
# on fungal proteomes from UniProt FASTA files.
#
# Features:
#   - Automatic Java environment detection
#   - Conda environment activation/deactivation for Java if needed
#   - PLAAC repository auto-setup from GitHub
#   - Parallel processing of large proteomes (chunked FASTA)
#   - Output compatible with prion prediction pipeline
#
# Requirements:
#   - Java Runtime Environment (JRE) 8+ (system or via Conda)
#   - Git (for initial PLAAC repository clone)
#   - Input: FASTA file (generated by funguild_preanalysis.R)
#
# Usage:
#   Rscript plaac_launcher.R -i sequences.fasta -o results/
#   Rscript plaac_launcher.R -i sequences.fasta --java-env plaac-java
#
# References:
#   Lancaster et al. (2014) BMC Bioinformatics
#   https://github.com/whitehead/plaac
################################################################################

suppressPackageStartupMessages({
  library(optparse)
  library(parallel)
})

################################################################################
# CONFIGURATION
################################################################################

# Standard directory structure (pipeline-compatible)
DATA_RAW_DIR       <- "data/raw"
DATA_CACHE_DIR     <- "data/cache"
DATA_PROCESSED_DIR <- "data/processed"
REPORTS_DIR        <- "reports"

# PLAAC settings
PLAAC_REPO_URL <- "https://github.com/whitehead/plaac.git"
PLAAC_TOOLS_DIR <- "R/tools"  # Base directory for external tools
PLAAC_DIR <- "plaac"          # PLAAC subdirectory within tools
PLAAC_JAR_RELATIVE <- "web/bin/plaac.jar"

# Default analysis parameters
DEFAULT_CORE_LENGTH <- 60           # Minimum PrLD length (Lcore)
DEFAULT_ALPHA <- 1.0                # 1.0 = pure S.cerevisiae background (best for fungi)
                                    # 0.5 = interpolate with organism-specific
                                    # 0.0 = pure organism-specific background

# Output options
# PLAAC produces 37 columns in summary output including:
#   - SEQid: sequence name from FASTA
#   - MW/MWstart/MWend/MWlen: Michelitsch-Weissman Q/N enrichment scores
#   - LLR/LLRstart/LLRend/LLRlen/NLLR: Log-likelihood ratio scores
#   - VITmaxrun: max consecutive PrD state in Viterbi parse
#   - COREscore/COREstart/COREend/CORElen/COREaa: Core prion domain scores
#   - PRDscore/PRDstart/PRDend/PRDlen/PRDaa: Full prion-like domain scores
#   - PROTlen: protein length
#   - HMMall/HMMvit: HMM log-likelihood ratios
#   - STARTaa/ENDaa: first/last 15 AA of PRD
#   - FInumaa/FImeanhydro/FImeancharge/FImeancombo/FImaxrun: FoldIndex disorder
#   - PAPAcombo/PAPAprop/PAPAfi/PAPAllr/PAPAllr2/PAPAcen/PAPAaa: PAPA prion scores

# Java environment
JAVA_CONDA_ENV <- "plaac-java"  # Default Conda env name for Java

# Parallel processing
CORES <- detectCores() - 1
if (CORES < 1) CORES <- 1

# Chunk size for large files (sequences per chunk)
CHUNK_SIZE <- 10000

# Global log file (set during main execution)
LOG_FILE <- NULL

################################################################################
# LOGGING AND VALIDATION
################################################################################

#' Log message to console and optionally to file
#' @param msg Message to log
#' @param log_file Optional path to log file
log_msg <- function(msg, log_file = LOG_FILE) {
  formatted <- sprintf("[%s] %s", format(Sys.time(), "%H:%M:%S"), msg)
  cat(formatted, "\n")
  if (!is.null(log_file)) {
    cat(formatted, "\n", file = log_file, append = TRUE)
  }
}

#' Validate FASTA file format
#' @param fasta_file Path to FASTA file
#' @return TRUE if valid, stops with error otherwise
validate_fasta <- function(fasta_file) {
  if (grepl("\\.gz$", fasta_file, ignore.case = TRUE)) {
    con <- gzfile(fasta_file, "rt")
  } else {
    con <- file(fasta_file, "rt")
  }

  first_line <- readLines(con, n = 1, warn = FALSE)
  close(con)

  if (length(first_line) == 0) {
    stop("Input file is empty")
  }

  if (!grepl("^>", first_line)) {
    stop("Input does not appear to be FASTA format (first line must start with '>')")
  }

  invisible(TRUE)
}

################################################################################
# JAVA ENVIRONMENT MANAGEMENT
################################################################################

#' Check if Java is available in current PATH
#' @return List with 'available' (logical) and 'version' (string or NULL)
check_java_available <- function() {
  result <- tryCatch({
    # java -version outputs to stderr
    output <- system2("java", "-version", stdout = TRUE, stderr = TRUE)
    
    # Parse version from output like: openjdk version "11.0.2" 2019-01-15
    version_line <- output[grep("version", output, ignore.case = TRUE)[1]]
    
    list(available = TRUE, version = version_line)
  }, error = function(e) {
    list(available = FALSE, version = NULL)
  }, warning = function(w) {
    # Warnings from stderr capture - still try to get output
    tryCatch({
      output <- suppressWarnings(
        system2("java", "-version", stdout = TRUE, stderr = TRUE)
      )
      version_line <- output[grep("version", output, ignore.case = TRUE)[1]]
      list(available = TRUE, version = version_line)
    }, error = function(e2) {
      list(available = FALSE, version = NULL)
    })
  })
  
  return(result)
}

#' Check if Conda is available
#' @return Logical
check_conda_available <- function() {
  result <- tryCatch({
    system2("conda", "--version", stdout = TRUE, stderr = TRUE)
    TRUE
  }, error = function(e) {
    FALSE
  })
  return(result)
}

#' List available Conda environments
#' @return Character vector of environment names
list_conda_envs <- function() {
  tryCatch({
    output <- system2("conda", c("env", "list"), stdout = TRUE, stderr = TRUE)
    # Parse environment names (skip header lines)
    env_lines <- output[!grepl("^#|^\\s*$", output)]
    env_names <- sapply(strsplit(env_lines, "\\s+"), `[`, 1)
    env_names <- env_names[env_names != "" & !is.na(env_names)]
    return(env_names)
  }, error = function(e) {
    return(character(0))
  })
}

#' Get Conda environment path
#' @param env_name Name of the Conda environment
#' @return Path to environment or NULL if not found
get_conda_env_path <- function(env_name) {
  tryCatch({
    output <- system2("conda", c("env", "list"), stdout = TRUE, stderr = TRUE)
    # Find line with our environment
    env_line <- output[grep(paste0("^", env_name, "\\s+"), output)]
    if (length(env_line) > 0) {
      # Extract path (second field)
      parts <- strsplit(env_line[1], "\\s+")[[1]]
      # Path is usually the last non-empty field
      path <- parts[length(parts)]
      if (dir.exists(path)) {
        return(path)
      }
    }
    return(NULL)
  }, error = function(e) {
    return(NULL)
  })
}

#' Run command with Conda environment activated
#' @param command Command to run
#' @param env_name Conda environment name
#' @param args Command arguments (character vector)
#' @return Exit code from command
run_with_conda_env <- function(command, env_name, args = character(0)) {
  # Get conda path for activation
  env_path <- get_conda_env_path(env_name)
  
  if (is.null(env_path)) {
    stop(sprintf("Conda environment '%s' not found", env_name))
  }
  
  # Build activation + command string
  # Works on both Unix and Windows (with conda init properly set up)
  if (.Platform$OS.type == "windows") {
    # Windows: use conda activate in same shell
    full_cmd <- sprintf(
      'conda activate %s && %s %s',
      env_name,
      command,
      paste(args, collapse = " ")
    )
    result <- system(full_cmd, intern = FALSE)
  } else {
    # Unix: source conda.sh then activate
    # Find conda.sh location
    conda_sh <- file.path(dirname(dirname(Sys.which("conda"))), 
                          "etc/profile.d/conda.sh")
    
    if (!file.exists(conda_sh)) {
      # Try alternative location
      conda_base <- system2("conda", c("info", "--base"), stdout = TRUE)
      conda_sh <- file.path(conda_base, "etc/profile.d/conda.sh")
    }
    
    if (file.exists(conda_sh)) {
      full_cmd <- sprintf(
        'source "%s" && conda activate %s && %s %s',
        conda_sh,
        env_name,
        command,
        paste(args, collapse = " ")
      )
    } else {
      # Fallback: use environment's bin directly
      full_cmd <- sprintf(
        '"%s/bin/%s" %s',
        env_path,
        command,
        paste(args, collapse = " ")
      )
    }
    result <- system(full_cmd, intern = FALSE)
  }
  
  return(result)
}

#' Setup Java environment (create Conda env if needed)
#' @param env_name Name for the Java Conda environment
#' @return Logical indicating success
setup_java_conda_env <- function(env_name = JAVA_CONDA_ENV) {
  cat(sprintf("\n=== Setting up Java Conda environment: %s ===\n", env_name))
  
  # Check if environment already exists
  existing_envs <- list_conda_envs()
  
  if (env_name %in% existing_envs) {
    cat(sprintf("✓ Environment '%s' already exists\n", env_name))
    return(TRUE)
  }
  
  # Create new environment with OpenJDK
  cat("Creating new Conda environment with OpenJDK 11...\n")
  cat("This may take a few minutes...\n\n")
  
  result <- system2(
    "conda",
    c("create", "-n", env_name, "openjdk=11", "-c", "conda-forge", "-y"),
    stdout = "", stderr = ""
  )
  
  if (result != 0) {
    stop(sprintf("Failed to create Conda environment '%s'", env_name))
  }
  
  cat(sprintf("✓ Created environment '%s' with OpenJDK 11\n", env_name))
  return(TRUE)
}

################################################################################
# PLAAC REPOSITORY MANAGEMENT
################################################################################

#' Setup PLAAC repository (clone from GitHub if needed)
#' @param base_dir Base directory of the project (where R/ folder is located)
#' @return Path to plaac.jar
setup_plaac_repository <- function(base_dir = ".") {
  # Build path: base_dir/R/tools/plaac/
  tools_dir <- file.path(base_dir, PLAAC_TOOLS_DIR)
  plaac_dir <- file.path(tools_dir, PLAAC_DIR)
  jar_path <- file.path(plaac_dir, PLAAC_JAR_RELATIVE)
  
  cat("\n=== Setting up PLAAC ===\n")
  
  # Check if already installed
  if (file.exists(jar_path)) {
    cat(sprintf("✓ PLAAC found at: %s\n", jar_path))
    return(normalizePath(jar_path))
  }
  
  # Check if directory exists but JAR is missing
  if (dir.exists(plaac_dir)) {
    cat(sprintf("PLAAC directory exists but JAR not found at expected location.\n"))
    cat(sprintf("Expected: %s\n", jar_path))
    cat("Attempting to locate JAR...\n")
    
    # Search for JAR
    found_jars <- list.files(plaac_dir, pattern = "plaac.*\\.jar$", 
                             recursive = TRUE, full.names = TRUE)
    
    if (length(found_jars) > 0) {
      jar_path <- found_jars[1]
      cat(sprintf("✓ Found PLAAC JAR at: %s\n", jar_path))
      return(normalizePath(jar_path))
    }
    
    stop("PLAAC JAR not found. Try removing the 'plaac' directory and re-running.")
  }
  
  # Clone repository
  cat(sprintf("Cloning PLAAC from: %s\n", PLAAC_REPO_URL))
  
  # Check git is available
  git_check <- tryCatch({
    system2("git", "--version", stdout = TRUE, stderr = TRUE)
    TRUE
  }, error = function(e) FALSE)
  
  if (!git_check) {
    stop("Git is required to clone PLAAC repository. Please install git.")
  }
  
  # Create R/tools/ directory structure if it doesn't exist
  if (!dir.exists(tools_dir)) {
    cat(sprintf("Creating tools directory: %s\n", tools_dir))
    dir.create(tools_dir, recursive = TRUE)
  }
  
  result <- system2("git", c("clone", PLAAC_REPO_URL, plaac_dir))
  
  if (result != 0) {
    stop("Failed to clone PLAAC repository")
  }
  
  # Verify JAR exists
  if (!file.exists(jar_path)) {
    # Search for it
    found_jars <- list.files(plaac_dir, pattern = "plaac.*\\.jar$",
                             recursive = TRUE, full.names = TRUE)
    if (length(found_jars) > 0) {
      jar_path <- found_jars[1]
    } else {
      stop("PLAAC JAR not found after cloning. Repository structure may have changed.")
    }
  }
  
  cat(sprintf("✓ PLAAC installed successfully\n"))
  cat(sprintf("  JAR location: %s\n", jar_path))
  
  return(normalizePath(jar_path))
}

################################################################################
# FASTA HANDLING
################################################################################

#' Count sequences in FASTA file
#' @param fasta_file Path to FASTA file
#' @return Integer count of sequences
count_fasta_sequences <- function(fasta_file) {
  if (grepl("\\.gz$", fasta_file, ignore.case = TRUE)) {
    con <- gzfile(fasta_file, "rt")
  } else {
    con <- file(fasta_file, "rt")
  }
  
  count <- 0L
  while (length(line <- readLines(con, n = 1000, warn = FALSE)) > 0) {
    count <- count + sum(grepl("^>", line))
  }
  
  close(con)
  return(count)
}

#' Split FASTA file into chunks for parallel processing
#' @param fasta_file Path to input FASTA file
#' @param chunk_size Number of sequences per chunk
#' @param output_dir Directory for chunk files
#' @return Vector of chunk file paths
split_fasta_file <- function(fasta_file, chunk_size, output_dir) {
  if (!dir.exists(output_dir)) {
    dir.create(output_dir, recursive = TRUE)
  }
  
  # Open input file
  if (grepl("\\.gz$", fasta_file, ignore.case = TRUE)) {
    con <- gzfile(fasta_file, "rt")
  } else {
    con <- file(fasta_file, "rt")
  }
  
  chunk_files <- character()
  chunk_num <- 1
  seq_count <- 0
  current_chunk <- character()
  current_seq <- character()
  in_sequence <- FALSE
  
  while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0) {
    if (grepl("^>", line)) {
      # Save previous sequence
      if (in_sequence && length(current_seq) > 0) {
        current_chunk <- c(current_chunk, current_seq)
        seq_count <- seq_count + 1
        
        # Check if chunk is full
        if (seq_count >= chunk_size) {
          # Write chunk
          chunk_file <- file.path(output_dir, 
                                  sprintf("chunk_%04d.fasta", chunk_num))
          writeLines(current_chunk, chunk_file)
          chunk_files <- c(chunk_files, chunk_file)
          
          # Reset
          chunk_num <- chunk_num + 1
          seq_count <- 0
          current_chunk <- character()
        }
      }
      
      # Start new sequence
      current_seq <- line
      in_sequence <- TRUE
      
    } else if (in_sequence) {
      # Continue sequence
      current_seq <- c(current_seq, line)
    }
  }
  
  # Save last sequence
  if (in_sequence && length(current_seq) > 0) {
    current_chunk <- c(current_chunk, current_seq)
  }
  
  # Write final chunk
  if (length(current_chunk) > 0) {
    chunk_file <- file.path(output_dir, sprintf("chunk_%04d.fasta", chunk_num))
    writeLines(current_chunk, chunk_file)
    chunk_files <- c(chunk_files, chunk_file)
  }
  
  close(con)
  return(chunk_files)
}

################################################################################
# PLAAC EXECUTION
################################################################################

#' Run PLAAC on a single FASTA file
#' @param fasta_file Path to input FASTA
#' @param output_file Path to output file (TSV)
#' @param jar_path Path to plaac.jar
#' @param core_length Core length parameter (default 60)
#' @param alpha Alpha parameter for background frequency interpolation (default 1.0)
#' @param java_env Conda environment with Java (NULL to use system Java)
#' @param per_residue Generate per-residue scores for plotting (default FALSE)
#' @param per_residue_file Path for per-residue output (if per_residue=TRUE)
#' @return Exit code
run_plaac_single <- function(fasta_file, output_file, jar_path,
                             core_length = DEFAULT_CORE_LENGTH,
                             alpha = DEFAULT_ALPHA,
                             java_env = NULL,
                             per_residue = FALSE,
                             per_residue_file = NULL) {
  
  # Build PLAAC command
  # PLAAC usage: java -jar plaac.jar -i input.fa -c CORE -a ALPHA > output.txt
  
  if (is.null(java_env)) {
    # Use system Java directly
    java_cmd <- "java"
  } else {
    # Use Java from Conda environment
    env_path <- get_conda_env_path(java_env)
    if (is.null(env_path)) {
      stop(sprintf("Java Conda environment '%s' not found", java_env))
    }
    
    if (.Platform$OS.type == "windows") {
      java_cmd <- file.path(env_path, "Library", "bin", "java.exe")
    } else {
      java_cmd <- file.path(env_path, "bin", "java")
    }
  }
  
  # Build the command for summary output (37 columns)
  cmd <- sprintf(
    '"%s" -jar "%s" -i "%s" -c %d -a %.2f > "%s"',
    java_cmd,
    jar_path,
    fasta_file,
    core_length,
    alpha,
    output_file
  )
  
  result <- system(cmd, intern = FALSE, ignore.stderr = FALSE)
  
  # Generate per-residue output if requested (for plotting/detailed analysis)
  if (per_residue && !is.null(per_residue_file)) {
    cmd_per_res <- sprintf(
      '"%s" -jar "%s" -i "%s" -c %d -a %.2f -p all > "%s"',
      java_cmd,
      jar_path,
      fasta_file,
      core_length,
      alpha,
      per_residue_file
    )
    
    result_per_res <- system(cmd_per_res, intern = FALSE, ignore.stderr = FALSE)
    
    if (result_per_res != 0) {
      warning("PLAAC per-residue output generation failed")
    }
  }
  
  return(result)
}

#' Run PLAAC with parallel chunk processing
#' @param fasta_file Path to input FASTA
#' @param output_dir Output directory
#' @param jar_path Path to plaac.jar
#' @param num_cores Number of parallel workers
#' @param core_length Core length parameter
#' @param alpha Alpha parameter for background frequency interpolation
#' @param java_env Conda environment with Java
#' @param per_residue Generate per-residue scores (can be large!)
#' @param db_prefix Database prefix for output naming
#' @return List with paths to output files
run_plaac_parallel <- function(fasta_file, output_dir, jar_path,
                               num_cores = CORES,
                               core_length = DEFAULT_CORE_LENGTH,
                               alpha = DEFAULT_ALPHA,
                               java_env = NULL,
                               per_residue = FALSE,
                               db_prefix = "fungi") {

  cat("\n=== Running PLAAC Analysis ===\n")

  # Count sequences
  cat("Counting sequences...\n")
  total_seqs <- count_fasta_sequences(fasta_file)
  cat(sprintf("Found %d sequences\n", total_seqs))

  # For PLAAC with alpha=1.0 (pure S.cerevisiae background), we can safely chunk
  # For alpha<1.0, the entire proteome should ideally be processed together
  # for accurate background frequency estimation

  if (alpha < 1.0 && total_seqs > CHUNK_SIZE) {
    cat("\n⚠ Warning: Using alpha < 1.0 with chunked processing.\n")
    cat("  Background frequencies will be estimated per-chunk, not globally.\n")
    cat("  For best results with alpha < 1.0, consider processing entire proteome.\n\n")
  }

  # Generate timestamped output filenames
  timestamp <- format(Sys.time(), "%Y%m%d_%H%M%S")

  # Dual output: full 37-column + standardized pipeline format
  full_output <- file.path(output_dir,
    sprintf("%s_plaac_full_%s.tsv", db_prefix, timestamp))
  predictions_output <- file.path(output_dir,
    sprintf("%s_plaac_predictions_%s.tsv", db_prefix, timestamp))
  per_residue_output <- if (per_residue) {
    file.path(output_dir,
      sprintf("%s_plaac_per_residue_%s.tsv", db_prefix, timestamp))
  } else {
    NULL
  }
  
  # Decide if we need chunking
  if (total_seqs <= CHUNK_SIZE || num_cores == 1) {
    # Process as single file
    cat("Processing as single file...\n")

    result <- run_plaac_single(
      fasta_file, full_output, jar_path,
      core_length, alpha, java_env,
      per_residue = per_residue,
      per_residue_file = per_residue_output
    )

    if (result != 0) {
      warning("PLAAC exited with non-zero status")
    }

    if (file.exists(full_output)) {
      cat(sprintf("✓ Full results (37 columns): %s\n", full_output))
    }
    if (per_residue && file.exists(per_residue_output)) {
      cat(sprintf("✓ Per-residue results: %s\n", per_residue_output))
    }

    return(list(
      full = full_output,
      predictions = predictions_output,
      per_residue = per_residue_output
    ))

  } else {
    # Split and process in parallel
    cat(sprintf("Splitting into chunks for parallel processing (%d cores)...\n",
                num_cores))

    # Create temp directory for chunks
    chunk_dir <- file.path(output_dir, "chunks_temp")
    if (dir.exists(chunk_dir)) {
      unlink(chunk_dir, recursive = TRUE)
    }

    # Ensure cleanup on exit (error handling)
    on.exit({
      if (dir.exists(chunk_dir)) {
        unlink(chunk_dir, recursive = TRUE)
      }
    }, add = TRUE)

    chunk_files <- split_fasta_file(fasta_file, CHUNK_SIZE, chunk_dir)
    cat(sprintf("Created %d chunks\n", length(chunk_files)))
    
    # Process chunks in parallel
    cat("Processing chunks...\n")
    
    process_chunk <- function(chunk_file) {
      chunk_name <- tools::file_path_sans_ext(basename(chunk_file))
      output_file <- file.path(chunk_dir, paste0(chunk_name, "_results.tsv"))
      per_res_file <- if (per_residue) {
        file.path(chunk_dir, paste0(chunk_name, "_per_residue.tsv"))
      } else {
        NULL
      }
      
      run_plaac_single(chunk_file, output_file, jar_path,
                       core_length, alpha, java_env,
                       per_residue = per_residue,
                       per_residue_file = per_res_file)
      
      return(list(summary = output_file, per_residue = per_res_file))
    }
    
    # Parallel execution
    if (.Platform$OS.type == "windows") {
      # Windows: sequential processing (parallel Java execution is complex)
      cat("Note: Running sequentially on Windows\n")
      result_files <- lapply(chunk_files, process_chunk)
    } else {
      result_files <- mclapply(chunk_files, process_chunk, mc.cores = num_cores)
    }
    
    # Combine full results
    cat("Combining chunk results...\n")

    # Combine summary files (keep header from first file only)
    first_file <- TRUE
    combined_con <- file(full_output, "wt")

    for (result in result_files) {
      if (file.exists(result$summary)) {
        lines <- readLines(result$summary, warn = FALSE)
        if (first_file) {
          writeLines(lines, combined_con)
          first_file <- FALSE
        } else {
          # Skip header lines (lines starting with #)
          data_lines <- lines[!grepl("^#", lines)]
          if (length(data_lines) > 0) {
            writeLines(data_lines, combined_con)
          }
        }
      }
    }
    close(combined_con)

    # Combine per-residue files if generated
    if (per_residue) {
      first_file <- TRUE
      combined_per_res <- file(per_residue_output, "wt")

      for (result in result_files) {
        if (!is.null(result$per_residue) && file.exists(result$per_residue)) {
          lines <- readLines(result$per_residue, warn = FALSE)
          if (first_file) {
            writeLines(lines, combined_per_res)
            first_file <- FALSE
          } else {
            # Skip header lines
            data_lines <- lines[!grepl("^#", lines)]
            if (length(data_lines) > 0) {
              writeLines(data_lines, combined_per_res)
            }
          }
        }
      }
      close(combined_per_res)
    }

    # Note: chunk_dir cleanup happens automatically via on.exit()

    cat(sprintf("✓ Full results (37 columns): %s\n", full_output))
    if (per_residue && file.exists(per_residue_output)) {
      cat(sprintf("✓ Per-residue results: %s\n", per_residue_output))
    }

    return(list(
      full = full_output,
      predictions = predictions_output,
      per_residue = per_residue_output
    ))
  }
}

################################################################################
# OUTPUT PROCESSING
################################################################################

#' Parse PLAAC full output and create standardized pipeline-compatible table
#' @param full_output Path to full PLAAC output file (37 columns)
#' @param predictions_output Path for standardized predictions output
#' @param score_threshold Threshold for Has_Prion_Domain (default: 20 for COREscore)
#' @return Data frame with standardized results
process_plaac_output <- function(full_output, predictions_output,
                                  score_threshold = 20) {
  cat("\n=== Processing PLAAC Output ===\n")

  # Read full PLAAC output (tab-separated)
  plaac_data <- tryCatch({
    read.table(full_output, header = TRUE, sep = "\t",
               stringsAsFactors = FALSE, quote = "", fill = TRUE)
  }, error = function(e) {
    warning(sprintf("Error reading PLAAC output: %s", e$message))
    return(NULL)
  })

  if (is.null(plaac_data) || nrow(plaac_data) == 0) {
    warning("No data in PLAAC output")
    return(NULL)
  }

  cat(sprintf("Read %d records from full PLAAC output\n", nrow(plaac_data)))

  # Create standardized pipeline-compatible output
  # Map PLAAC columns to standard format
  # NOTE: Force numeric conversion to prevent string comparison bugs
  standardized <- data.frame(
    Protein_ID = plaac_data$SEQid,
    Organism = extract_organism_from_seqid(plaac_data$SEQid),
    Prion_Score = if ("COREscore" %in% names(plaac_data)) as.numeric(plaac_data$COREscore) else NA,
    LLR_Score = if ("LLR" %in% names(plaac_data)) as.numeric(plaac_data$LLR) else NA,
    PAPA_Score = if ("PAPAcombo" %in% names(plaac_data)) as.numeric(plaac_data$PAPAcombo) else NA,
    Has_Prion_Domain = if ("COREscore" %in% names(plaac_data)) {
      as.numeric(plaac_data$COREscore) >= score_threshold
    } else FALSE,
    Domain_Start = if ("COREstart" %in% names(plaac_data)) as.numeric(plaac_data$COREstart) else NA,
    Domain_End = if ("COREend" %in% names(plaac_data)) as.numeric(plaac_data$COREend) else NA,
    Domain_Length = if ("CORElen" %in% names(plaac_data)) as.numeric(plaac_data$CORElen) else NA,
    Domain_Sequence = if ("COREaa" %in% names(plaac_data)) plaac_data$COREaa else NA,
    Protein_Length = if ("PROTlen" %in% names(plaac_data)) as.numeric(plaac_data$PROTlen) else NA,
    stringsAsFactors = FALSE
  )

  # Write standardized output
  write.table(standardized, predictions_output, sep = "\t",
              row.names = FALSE, quote = FALSE)
  cat(sprintf("✓ Standardized predictions written to: %s\n", predictions_output))

  # Summary statistics
  n_positive <- sum(standardized$Has_Prion_Domain, na.rm = TRUE)
  cat(sprintf("  Total proteins: %d\n", nrow(standardized)))
  cat(sprintf("  Prion domain predictions (COREscore >= %d): %d (%.1f%%)\n",
              score_threshold, n_positive,
              100 * n_positive / nrow(standardized)))

  return(standardized)
}

#' Extract organism name from FASTA sequence ID
#' @param seqid Vector of sequence IDs (e.g., "sp|P12345|NAME_ORGANISM")
#' @return Vector of organism names or "Unknown" if not parseable
extract_organism_from_seqid <- function(seqid) {
  # Try to extract organism from UniProt-style headers
  # Format: sp|ACCESSION|NAME_ORGANISM or tr|ACCESSION|NAME_ORGANISM
  # Or: >ACCESSION|TAXID|Organism name (from data_preanalysis.R FASTA)

  organisms <- sapply(seqid, function(id) {
    # Try UniProt format: sp|P12345|NAME_ORGNAME
    if (grepl("\\|[^|]+_[A-Z]+$", id)) {
      parts <- strsplit(id, "\\|")[[1]]
      if (length(parts) >= 3) {
        name_org <- parts[3]
        org_part <- sub("^[^_]+_", "", name_org)
        return(org_part)
      }
    }

    # Try pipeline FASTA format: ACCESSION|TAXID|Organism
    if (grepl("\\|\\d+\\|", id)) {
      parts <- strsplit(id, "\\|")[[1]]
      if (length(parts) >= 3) {
        return(parts[3])
      }
    }

    # Fallback
    return("Unknown")
  }, USE.NAMES = FALSE)

  return(organisms)
}

################################################################################
# MAIN EXECUTION
################################################################################

main <- function() {
  # Define command-line options
  option_list <- list(
    make_option(
      c("-i", "--input"),
      type = "character",
      default = NULL,
      help = "Input FASTA file (REQUIRED)",
      metavar = "FILE"
    ),
    make_option(
      c("-o", "--output-dir"),
      type = "character",
      default = DATA_PROCESSED_DIR,
      help = sprintf("Output directory [default: %s]", DATA_PROCESSED_DIR),
      metavar = "DIR"
    ),
    make_option(
      c("-d", "--db"),
      type = "character",
      default = "fungi",
      help = "Database prefix for output naming (sprot/trembl/fungi) [default: %default]",
      metavar = "NAME"
    ),
    make_option(
      c("-c", "--core-length"),
      type = "integer",
      default = DEFAULT_CORE_LENGTH,
      help = "Core length for PLAAC analysis [default: %default]",
      metavar = "INT"
    ),
    make_option(
      c("-a", "--alpha"),
      type = "double",
      default = DEFAULT_ALPHA,
      help = "Alpha for background freq interpolation (1.0=S.cerevisiae, 0=organism-specific) [default: %default]",
      metavar = "FLOAT"
    ),
    make_option(
      c("-j", "--java-env"),
      type = "character",
      default = NULL,
      help = "Conda environment with Java (if not in system PATH)",
      metavar = "ENV_NAME"
    ),
    make_option(
      c("-n", "--cores"),
      type = "integer",
      default = CORES,
      help = sprintf("Number of CPU cores [default: %d]", CORES),
      metavar = "INT"
    ),
    make_option(
      c("-p", "--per-residue"),
      action = "store_true",
      default = FALSE,
      help = "Also generate per-residue scores for plotting (can be large!)"
    ),
    make_option(
      c("--setup-java"),
      action = "store_true",
      default = FALSE,
      help = "Create Conda environment with Java and exit"
    ),
    make_option(
      c("--setup-plaac"),
      action = "store_true",
      default = FALSE,
      help = "Download PLAAC repository and exit"
    )
  )
  
  opt_parser <- OptionParser(
    option_list = option_list,
    usage = "usage: %prog -i INPUT.fasta [options]",
    description = paste(
      "\n=== PLAAC Launcher v1.0 ===",
      "Run PLAAC (Prion-Like Amino Acid Composition) analysis on proteome FASTA files.",
      "\nPart of the fungal prion domain prediction pipeline.",
      "\nOutput includes 37 columns: COREscore, LLR, PAPA, FoldIndex disorder, and more.",
      sep = "\n"
    ),
    epilogue = paste(
      "\nExamples:",
      "  # Basic usage with system Java:",
      "  Rscript R/plaac.R -i sequences.fasta",
      "",
      "  # Pipeline integration (with db prefix):",
      "  Rscript R/plaac.R -i data/processed/sprot_fungi_sequences.fasta --db sprot",
      "",
      "  # Full output with per-residue scores:",
      "  Rscript R/plaac.R -i sequences.fasta -p",
      "",
      "  # Using Conda Java environment:",
      "  Rscript R/plaac.R -i sequences.fasta -j plaac-java",
      "",
      "  # Setup Java environment first:",
      "  Rscript R/plaac.R --setup-java",
      "",
      "  # Custom parameters:",
      "  Rscript R/plaac.R -i sequences.fasta -c 50 -n 8 --db trembl",
      "",
      "\nReferences:",
      "  Lancaster et al. (2014) BMC Bioinformatics",
      "  https://github.com/whitehead/plaac",
      sep = "\n"
    )
  )
  
  opt <- parse_args(opt_parser)
  
  # Print banner
  cat("\n")
  cat("================================================================================\n")
  cat("PLAAC LAUNCHER v1.0 - Prion-Like Amino Acid Composition Analysis\n")
  cat("================================================================================\n")
  
  # Handle setup-only modes
  if (opt$`setup-java`) {
    cat("\n=== Java Environment Setup Mode ===\n")
    
    if (!check_conda_available()) {
      stop("Conda not found. Please install Conda first.")
    }
    
    setup_java_conda_env(JAVA_CONDA_ENV)
    
    cat("\n✓ Java environment setup complete!\n")
    cat(sprintf("  Use with: Rscript plaac_launcher.R -i input.fasta -j %s\n", 
                JAVA_CONDA_ENV))
    return(invisible())
  }
  
  if (opt$`setup-plaac`) {
    cat("\n=== PLAAC Repository Setup Mode ===\n")
    jar_path <- setup_plaac_repository(".")
    cat("\n✓ PLAAC setup complete!\n")
    cat(sprintf("  Location: %s\n", file.path(PLAAC_TOOLS_DIR, PLAAC_DIR)))
    cat(sprintf("  JAR: %s\n", jar_path))
    return(invisible())
  }
  
  # Validate required arguments
  if (is.null(opt$input)) {
    print_help(opt_parser)
    stop("\nError: --input is required!", call. = FALSE)
  }

  if (!file.exists(opt$input)) {
    stop(sprintf("Input file not found: %s", opt$input))
  }

  # Validate FASTA format
  cat("\n--- Validating Input ---\n")
  validate_fasta(opt$input)
  cat(sprintf("✓ Valid FASTA file: %s\n", basename(opt$input)))
  
  # Check/setup Java
  cat("\n--- Checking Java Environment ---\n")
  java_status <- check_java_available()
  java_env_to_use <- opt$`java-env`
  
  if (java_status$available) {
    cat(sprintf("✓ System Java available: %s\n", java_status$version))
  } else {
    cat("✗ System Java not found\n")
    
    if (is.null(java_env_to_use)) {
      # Check if Conda is available and if default Java env exists
      if (check_conda_available()) {
        existing_envs <- list_conda_envs()
        
        if (JAVA_CONDA_ENV %in% existing_envs) {
          cat(sprintf("  Using Conda environment: %s\n", JAVA_CONDA_ENV))
          java_env_to_use <- JAVA_CONDA_ENV
        } else {
          cat("\nNo Java environment found. Options:\n")
          cat("  1. Install Java system-wide\n")
          cat(sprintf("  2. Run: Rscript plaac_launcher.R --setup-java\n"))
          cat(sprintf("  3. Specify existing Java Conda env with: -j ENV_NAME\n"))
          stop("Java is required to run PLAAC")
        }
      } else {
        stop("Neither system Java nor Conda found. Please install Java.")
      }
    } else {
      # User specified Java environment
      if (check_conda_available()) {
        existing_envs <- list_conda_envs()
        if (!(java_env_to_use %in% existing_envs)) {
          stop(sprintf("Conda environment '%s' not found", java_env_to_use))
        }
        cat(sprintf("  Using Conda environment: %s\n", java_env_to_use))
      } else {
        stop("Conda not available but --java-env specified")
      }
    }
  }
  
  # Setup PLAAC
  jar_path <- setup_plaac_repository(".")
  
  # Create output directory
  if (!dir.exists(opt$`output-dir`)) {
    dir.create(opt$`output-dir`, recursive = TRUE)
  }
  
  # Run analysis
  cat("\n--- Analysis Parameters ---\n")
  cat(sprintf("Input file:      %s\n", opt$input))
  cat(sprintf("Output dir:      %s\n", opt$`output-dir`))
  cat(sprintf("Database prefix: %s\n", opt$db))
  cat(sprintf("Core length:     %d\n", opt$`core-length`))
  cat(sprintf("Alpha:           %.2f\n", opt$alpha))
  cat(sprintf("CPU cores:       %d\n", opt$cores))
  cat(sprintf("Per-residue:     %s\n", ifelse(opt$`per-residue`, "YES", "NO")))
  if (!is.null(java_env_to_use)) {
    cat(sprintf("Java env:        %s\n", java_env_to_use))
  }

  start_time <- Sys.time()

  # Run PLAAC
  output_files <- run_plaac_parallel(
    fasta_file = opt$input,
    output_dir = opt$`output-dir`,
    jar_path = jar_path,
    num_cores = opt$cores,
    core_length = opt$`core-length`,
    alpha = opt$alpha,
    java_env = java_env_to_use,
    per_residue = opt$`per-residue`,
    db_prefix = opt$db
  )
  
  # Process output - generate standardized predictions file
  if (file.exists(output_files$full)) {
    results <- process_plaac_output(output_files$full, output_files$predictions)

    if (!is.null(results)) {
      cat(sprintf("\n✓ Analysis complete: %d sequences processed\n", nrow(results)))
    }
  }

  end_time <- Sys.time()
  elapsed <- difftime(end_time, start_time, units = "mins")

  # Summary
  cat("\n================================================================================\n")
  cat("ANALYSIS COMPLETE\n")
  cat("================================================================================\n")
  cat(sprintf("Execution time: %.1f minutes\n", as.numeric(elapsed)))
  cat("\nOutput files:\n")
  cat(sprintf("  Full (37 columns):       %s\n", output_files$full))
  cat(sprintf("  Pipeline predictions:    %s\n", output_files$predictions))
  if (opt$`per-residue` && !is.null(output_files$per_residue)) {
    cat(sprintf("  Per-residue scores:      %s\n", output_files$per_residue))
  }
  cat("\nFull output columns include:\n")
  cat("  - COREscore/LLR: Prion-like domain scores\n")
  cat("  - PAPA scores: Prion aggregation propensity\n")
  cat("  - FoldIndex: Intrinsic disorder predictions\n")
  cat("  - MW: Michelitsch-Weissman Q/N enrichment\n")
  cat("  - Sequence positions and amino acid sequences\n")
  cat("\nPipeline predictions columns:\n")
  cat("  - Protein_ID, Organism, Prion_Score, Has_Prion_Domain\n")
  cat("  - Domain_Start, Domain_End, Domain_Length, Domain_Sequence\n")
  cat("================================================================================\n\n")
}

################################################################################
# SCRIPT ENTRY POINT
################################################################################

if (!interactive()) {
  main()
}
